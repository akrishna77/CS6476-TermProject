{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x and y\n",
      "(77, 30008)\n",
      "(77,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "with open(\"data/annotations_train.json\") as f1:\n",
    "    data=json.load(f1)\n",
    "    \n",
    "\n",
    "for key,value in data.items():\n",
    "    img_path=\"./data/sg_dataset/sg_train_images/\"+key\n",
    "    img=Image.open(img_path)\n",
    "    [h,w]=img.size  \n",
    "    img=np.asarray(img.resize((100,100),Image.ANTIALIAS))\n",
    "    img=img.flatten()\n",
    "    for sets in value:\n",
    "        sub=sets[\"subject\"]\n",
    "        ob=sets[\"object\"]\n",
    "        sub_box=(sub[\"bbox\"])\n",
    "        ob_box=(ob[\"bbox\"])\n",
    "        \n",
    " \n",
    "        y_min_sub=round((sub_box[0]/h)*100)\n",
    "        y_max_sub=round((sub_box[1]/h)*100)\n",
    "        x_min_sub=round((sub_box[2]/w)*100)\n",
    "        x_max_sub=round((sub_box[3]/w)*100)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_min_ob=round((ob_box[0]/h)*100)\n",
    "        y_max_ob=round((ob_box[1]/h)*100)\n",
    "        x_min_ob=round((ob_box[2]/w)*100)\n",
    "        x_max_ob=round((ob_box[3]/w)*100)\n",
    "        \n",
    "\n",
    "        \n",
    "        feature_vector=np.append(img,[y_min_sub,y_max_sub,x_min_sub,x_max_sub,y_min_ob,y_max_ob,x_min_ob,x_max_ob])      \n",
    "        #feature_vector=np.append(feature_vector,ob_box)\n",
    "        x.append(feature_vector)\n",
    "        y.append(sets[\"predicate\"])\n",
    "  \n",
    "    \n",
    "           \n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "np.save(\"features.npy\",x)\n",
    "np.save(\"labels.npy\",y)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
